{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npT9yREcYLvf"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmmZzMBtYNK2",
        "outputId": "e4436483-0cd5-4204-e096-7165b0b555d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "from torchvision.transforms import Compose,ToTensor, Normalize, RandomHorizontalFlip, RandomAffine\n",
        "from torchvision.datasets.cifar import CIFAR10,CIFAR100\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pdb\n",
        "import copy\n",
        "import random\n",
        "from random import randint\n",
        "from itertools import combinations\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78cBc-HwYcde"
      },
      "source": [
        "# Model Class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PYAvV0fYdcO",
        "outputId": "0537c8f1-9586-45aa-bd73-ed88984195fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Use GPU? True\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 32, 32]           1,792\n",
            "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
            "              ReLU-3           [-1, 64, 32, 32]               0\n",
            "            Conv2d-4           [-1, 64, 32, 32]          36,928\n",
            "       BatchNorm2d-5           [-1, 64, 32, 32]             128\n",
            "              ReLU-6           [-1, 64, 32, 32]               0\n",
            "            Conv2d-7          [-1, 128, 32, 32]          73,856\n",
            "       BatchNorm2d-8          [-1, 128, 32, 32]             256\n",
            "              ReLU-9          [-1, 128, 32, 32]               0\n",
            "           Conv2d-10          [-1, 128, 32, 32]         147,584\n",
            "      BatchNorm2d-11          [-1, 128, 32, 32]             256\n",
            "             ReLU-12          [-1, 128, 32, 32]               0\n",
            "           Conv2d-13          [-1, 256, 32, 32]         295,168\n",
            "      BatchNorm2d-14          [-1, 256, 32, 32]             512\n",
            "             ReLU-15          [-1, 256, 32, 32]               0\n",
            "           Conv2d-16          [-1, 256, 32, 32]         590,080\n",
            "      BatchNorm2d-17          [-1, 256, 32, 32]             512\n",
            "             ReLU-18          [-1, 256, 32, 32]               0\n",
            "           Conv2d-19          [-1, 256, 32, 32]         590,080\n",
            "      BatchNorm2d-20          [-1, 256, 32, 32]             512\n",
            "             ReLU-21          [-1, 256, 32, 32]               0\n",
            "        AvgPool2d-22            [-1, 256, 8, 8]               0\n",
            "           Conv2d-23            [-1, 512, 8, 8]       1,180,160\n",
            "      BatchNorm2d-24            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-25            [-1, 512, 8, 8]               0\n",
            "           Conv2d-26            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-27            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-28            [-1, 512, 8, 8]               0\n",
            "           Conv2d-29            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-30            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-31            [-1, 512, 8, 8]               0\n",
            "           Conv2d-32            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-33            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-34            [-1, 512, 8, 8]               0\n",
            "           Conv2d-35            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-36            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-37            [-1, 512, 8, 8]               0\n",
            "           Conv2d-38            [-1, 512, 8, 8]       2,359,808\n",
            "      BatchNorm2d-39            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-40            [-1, 512, 8, 8]               0\n",
            "        MaxPool2d-41            [-1, 512, 4, 4]               0\n",
            "           Linear-42                 [-1, 4096]      33,558,528\n",
            "             ReLU-43                 [-1, 4096]               0\n",
            "           Linear-44                 [-1, 4096]      16,781,312\n",
            "             ReLU-45                 [-1, 4096]               0\n",
            "           Linear-46                  [-1, 100]         409,600\n",
            "================================================================\n",
            "Total params: 65,472,576\n",
            "Trainable params: 65,472,576\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.01\n",
            "Forward/backward pass size (MB): 31.81\n",
            "Params size (MB): 249.76\n",
            "Estimated Total Size (MB): 281.58\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "print('Use GPU?', use_cuda)\n",
        "\n",
        "num_train = 50000\n",
        "num_classes = 100\n",
        "\n",
        "# Define a VGG-16\n",
        "class model(nn.Module):\n",
        "    def __init__(self, num_classes=100):\n",
        "        super(model, self).__init__()\n",
        "        self.num_filters = 64\n",
        "        self.layer1 = nn.Sequential(\n",
        "            nn.Conv2d(3, self.num_filters, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters),\n",
        "            nn.ReLU())\n",
        "        self.layer2 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters, self.num_filters, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters),\n",
        "            nn.ReLU())\n",
        "        self.layer3 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters, self.num_filters*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*2),\n",
        "            nn.ReLU())\n",
        "        self.layer4 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*2,self.num_filters*2, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*2),\n",
        "            nn.ReLU())\n",
        "        self.layer5 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*2, self.num_filters*4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*4),\n",
        "            nn.ReLU())\n",
        "        self.layer6 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*4, self.num_filters*4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*4),\n",
        "            nn.ReLU())\n",
        "        self.layer7 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*4, self.num_filters*4, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*4),\n",
        "            nn.ReLU(),\n",
        "            nn.AvgPool2d(kernel_size = 4, stride = 4))\n",
        "        self.layer8 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*4, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU())\n",
        "        self.layer9 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*8, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU())\n",
        "        self.layer10 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*8, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU())\n",
        "        self.layer11 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*8, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU())\n",
        "        self.layer12 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*8, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU())\n",
        "        self.layer13 = nn.Sequential(\n",
        "            nn.Conv2d(self.num_filters*8, self.num_filters*8, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(self.num_filters*8),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
        "\n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(self.num_filters*8*16, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes,bias = False))\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.layer1(x)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = self.layer5(out)\n",
        "        out = self.layer6(out)\n",
        "        out = self.layer7(out)\n",
        "        out = self.layer8(out)\n",
        "        out = self.layer9(out)\n",
        "        out = self.layer10(out)\n",
        "        out = self.layer11(out)\n",
        "        out = self.layer12(out)\n",
        "        out = self.layer13(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc(out)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "my_model = model()\n",
        "\n",
        "if use_cuda:\n",
        "  my_model = my_model.cuda()  # transfer model to GPU\n",
        "\n",
        "\n",
        "summary(my_model,(3,32,32))\n",
        "num_epochs = 200\n",
        "minibatch_size = 100\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ib_T3OiY8Qu"
      },
      "source": [
        "# Data preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ushtClc1p4hk",
        "outputId": "621c83f0-c6e3-4e57-ed54-22ccbc2d3145"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "batch_size = 100\n",
        "num_workers = 8\n",
        "train_transform = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
        "    RandomHorizontalFlip(p=0.5),\n",
        "    RandomAffine(degrees = 0, translate = (0.125,0.125))\n",
        "])\n",
        "\n",
        "test_transform = Compose([\n",
        "    ToTensor(),\n",
        "    Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "])\n",
        "\n",
        "# Load Data\n",
        "train_dataset = CIFAR100(\n",
        "    root=\"dataset/\", train=True, transform=train_transform, download=True\n",
        ")\n",
        "test_dataset = CIFAR100(\n",
        "    root=\"dataset/\", train=False, transform=test_transform, download=True\n",
        ")\n",
        "\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers = num_workers, shuffle=True, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, num_workers=num_workers,\n",
        "                         shuffle=False, pin_memory=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mbcx0OmUinbF"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KD9bCnl35CuU"
      },
      "outputs": [],
      "source": [
        "# Create new model\n",
        "my_model = model()\n",
        "if use_cuda:\n",
        "  my_model = my_model.cuda()\n",
        "\n",
        "\n",
        "# Different Hyper-parameters for different layers\n",
        "my_list = ['fc.0.weight', 'fc.0.bias','fc1.0.weight', 'fc1.0.bias','fc2.0.weight', 'fc2.0.bias']\n",
        "new_params = list(filter(lambda kv: kv[0] in my_list, my_model.named_parameters()))\n",
        "base_params = list(filter(lambda kv: kv[0] not in my_list, my_model.named_parameters()))\n",
        "new_params = [p[1] for p in new_params]\n",
        "base_params = [p[1] for p in base_params]\n",
        "optimizer = optim.SGD([{'params': base_params},\n",
        "          {'params': new_params, 'lr':0.007, 'momentum': 0.982, 'weight_decay': 0.00135}\n",
        "      ], lr=0.011, momentum=0.98, weight_decay = 0.00115, nesterov=True)\n",
        "\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "\n",
        "  if epoch%20==0:\n",
        "    optimizer.param_groups[0]['lr'] *=0.6\n",
        "\n",
        "  my_model.train()\n",
        "  for which_mb, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "\n",
        "    if use_cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "\n",
        "\n",
        "    # Forward pass to get the loss\n",
        "    output = my_model(images)\n",
        "    optimizer.zero_grad()\n",
        "    loss= criterion(output, labels)\n",
        "    # Backward and compute the gradient\n",
        "    loss.backward()  #backpropragation\n",
        "    optimizer.step() #update the weights/parameters\n",
        "\n",
        "\n",
        "  # Test accuracy\n",
        "  my_model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  for i, (images, labels) in enumerate(test_loader):\n",
        "    if use_cuda:\n",
        "      images = images.cuda()\n",
        "      labels = labels.cuda()\n",
        "    with torch.no_grad():\n",
        "      outputs = my_model(images)\n",
        "\n",
        "\n",
        "    p_max, predicted = torch.max(outputs, 1)\n",
        "    correct += (predicted == labels).sum()\n",
        "\n",
        "    total += labels.size(0)\n",
        "  # test_accuracy_hard[epoch,counter] = float(correct_hard)/total\n",
        "\n",
        "  print('Epoch: {}, Test accuracy soft: {:.4f}' .format(epoch+1,float(correct)/total))#,test_accuracy_hard[epoch,counter])) # training_accuracy\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v4PeldmdP4jR"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
